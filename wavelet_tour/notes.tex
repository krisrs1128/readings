\documentclass{article}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{amsmath, amsfonts, amssymb}
\input{preamble.tex}

\title{Notes}
\author{Kris Sankaran}

\begin{document}

\section{Sparse Representations}
\label{sec:chapter_1}

Sparse representations are useful. We'll also want overcomplete dictionaries,
because things can be expressed sparsely when there is some redundancy, just
like in ordinary language.

The fourier transform represents regular, time-invariant signals in a sparse
way, and is ideal there. But it is cumbersome when we care about transient
phenomena. In this case, it can be better to use wavelets. Here we write

\begin{align}
  f = \sum_{j, n} \left<f, \psi_{j, n}\right> \psi_{j, n}
\end{align}
where $\psi_{j, n}$ are dilations and translations of the haar function (-1 and
1 on the two halves of the unit interval) and the correlation is
\begin{align}
\left<f, \psi_{j, n}\right> &= \int f\left(t\right) \psi_{j, n}\left(t\right) dt
\end{align}

It is necessary to go back and forth between continuous functions and discrete
sequences in this field. Continuous functions are the right objects for
developing theory, while discrete sequences are necessary for actual computer
implementations.

First we look at sampling with linear approximations. We sample a signal $f$
supported on the unit interval using a low-pass response, resulting in the
length $N$ array,

\begin{align}
f\left[n\right] &= \left<f\left(x\right), \varphi_{s}\left(x - ns\right)\right>,
\end{align}
we hope that the $\varphi_{s}$'s make up a basis of an appropriate approximation
space.

The projection onto some (other?) orthogonal basis $\bar{g}_{1}, \dots,
\bar{g}_{N}$ looks like
\begin{align}
\bar{f}_{N}\left(x\right) &= \sum_{m = 0}^{N - 1} \left<\bar{f}, \bar{g}_{m}\right>\bar{g}_{m}\left(x\right)
\end{align}
Really we want to adapt sampling points to the signal (ir)regularity. For
nonlinear approximations, we don't just apply a linear approximation to the
array $f\left[n\right]$. For example, if we use thresholding, we choose the top
$M$ largest (in absolute value) coefficients $\left<f, g_m\right>$ and make
approximations using just these.

For compression, one approach is to quantize the wavelet coefficients. Also,
sometimes you can improve performance by incorporating known geometric
regularity (e.g., curvelets).

We might imagine noise is introduce in the analog to digital sampling,
\begin{align}
X\left[n\right] &= f\left[n\right] + W\left[n\right]
\end{align}
for noise $W$. We will recover an estimate $\tilde{F} = DX$ using an operator
$D$. The risk is

\begin{align}
r\left(D, f\right) &= \Earg{\|f - DX\|^{2}}
\end{align}
and the goal will be either to minimize a bayes risk (which puts a prior $\pi$
on the signal $f$) or to be minimax and minimize over all $f\in \Theta$.

Donoho and Johnstone showed that thresholding wavelet coefficients provides
adaptive smoothing, averaging different amounts depending on how regular the
function appears. They also show that this procedure gets within a log-factor of
the oracle error when you know the actual support of nonzero coefficients.

Gabor was interested in time-frequency localizations of functions, motivated by
the uncertainty principle (which gives a lower bound on the product of variances
in these two domains). Building dictionaries amounts to tiling this
time-frequency plane up to this width constraint.

Two kinds of dictionaries are the windowed fourier transform and the continuous
wavelet transform, which we denote by $Sf\left(u, \xi\right)$ and $Wf\left(u,
s\right)$, respectively, where $u$ is position, $\xi$ is frequency, and $s$ is
scale.

Wavelet orthonormal bases are a subclass that create a perfect tiling. Wavelet
packet bases are a generalization that produce tilings that aren't nested w.r.t
a single time (over frequencies). The local cosine basis is the same idea but
reversing roles of time and frequency. These tiling portraits seem quite useful.

When working with dictionaries, the two basic problems are dual-syntehsis
(compute the project $f_{\Lambda}$ onto subset of vectors $V_{\Lambda}$) and
dual-analysis (compute coefficients w.r.t some basis elements).

We'll often want to find which subset $\Lambda$ in the overcomplete basis
provide a good approximation, it will turn out that this solves the lagrangian

\begin{align}
\mathcal{L}_{0}\left(T, f, \Lambda\right) &= \|f - f_{\Lambda}\|^{2} + T^{2}\absarg{\Lambda}
\end{align}

If you weren't working with orthogonal basis vectors, you have more flexibility,
but have to come up with a reasonable search strategy. Two common ones are
matching pursuit (similar to forwards stepwise) and basis pursuit (similar to
lasso). These will work if an incoherence property is satisfied,

\begin{align}
\max_{q \notin \Lambda_{T}} \sum_{p \in \Lambda_{T}} \absarg{\left<\tilde{\varphi}_p, \varphi_q\right>} < 1
\end{align}
which basically means dictionary elements in $\Lambda_{T}$ are not too close to
those in it.

Another type of problem that is often interesting ask you to find $f$ after it
has been passed through some operator $U$, which loses some information,
\begin{align}
Y = U f + W,
\end{align}
this is called an inverse problem. A first approach is to use an SVD, based on
eigenvectors of $U$. Or, your can threshold the diagonal elements.

Superresolution is the problem of recovering signals that have been
undersampled. Important cases are compressive sensing (solving this lets you
skip lots of acquisition / sensing and get nearly as good results) and blind
source separation

\section{The Fourier Kingdom}
\label{sec:chapter_2}

Linear time invariance of an operator $L$ means

\begin{align}
g\left(t\right) = Lf\left(t\right) \implies g\left(t - \tau\right) = L f_{\tau}\left(t\right)
\end{align}

The impulse response of hte operator $L$ is defined by

\begin{align}
h\left(t\right) &= L \delta\left(t\right)
\end{align}
and by time invariance,
\begin{align}
Lf\left(t\right) &= h\star f\left(t\right)
\end{align}
where $\star$ denotes convolution.

The complex exponentials are eigenvectors of convolutions, with eigenvalues
equal to the fourier transforms at the associated frequency.

Write the fourier integral
\begin{align}
\hat{f}\left(\omega\right) &= \int f\left(t\right) e^{-i\omega t} dt
\end{align}
for the ``amount'' of oscillation w.r.t frequency $\omega$.

\end{document}
